[
  {
    "content": "The goal of regression is to predict the value of one or more continuous target vari- ables t given the value of a D-dimensional vector x of input variables. Typically we are given a training data set comprising N observations {n}, where n = 1, ... , N, together with corresponding target values {tn }, and the goal is to predict the value of t for a new value of x. To do this, we formulate a function y(x, w) whose values for new inputs x constitute the predictions for the corresponding values of t, and where w represents a vector of parameters that can be learned from the training data.",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": []
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6779,
          1.4276,
          6.5782,
          1.4279,
          6.5781,
          2.5929,
          1.6778,
          2.5926
        ]
      }
    ]
  },
  {
    "content": "The simplest model for regression is one that involves a linear combination of the input variables:",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": []
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6786,
          2.5906,
          6.5788,
          2.5879,
          6.579,
          2.9205,
          1.6787,
          2.9233
        ]
      }
    ]
  },
  {
    "content": "where x = (x1, ... , XD)T. The term linear regression sometimes refers specifically to this form of model. The key property of this model is that it is a linear function of the parameters wo, ... , wp. It is also, however, a linear function of the input variables xį, and this imposes significant limitations on the model.",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": []
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6812,
          3.361,
          6.5764,
          3.3587,
          6.5767,
          4.0308,
          1.6815,
          4.033
        ]
      }
    ]
  },
  {
    "content": "We can extend the class of models defined by (4.1) by considering linear com- binations of fixed nonlinear functions of the input variables, of the form",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "4.1.1 Basis functions",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": [
        "(4.1)"
      ]
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6779,
          4.3849,
          6.5642,
          4.3917,
          6.5638,
          4.7275,
          1.6775,
          4.7208
        ]
      }
    ]
  },
  {
    "content": "where øj(x) are known as basis functions. By denoting the maximum value of the index j by M - 1, the total number of parameters in this model will be M.",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "4.1.1 Basis functions",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": []
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6773,
          5.4786,
          6.5685,
          5.4745,
          6.5688,
          5.8084,
          1.6776,
          5.8125
        ]
      }
    ]
  },
  {
    "content": "The parameter w0 allows for any fixed offset in the data and is sometimes called a bias parameter (not to be confused with bias in a statistical sense). It is often convenient to define an additional dummy basis function ¢0(x) whose value is fixed at ¢0(x) = 1 so that (4.2) becomes",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "4.1.1 Basis functions",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": [
        "(4.2)"
      ]
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6772,
          5.8107,
          6.5711,
          5.7952,
          6.5732,
          6.4591,
          1.6793,
          6.4746
        ]
      }
    ]
  },
  {
    "content": "where w = (wo, ... , WM-1)T and $ = (do, ... , PM-1)T. We can represent the model (4.3) using a neural network diagram, as shown in Figure 4.1.",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "4.1.1 Basis functions",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [
        "Figure 4.1"
      ],
      "formula_references": [
        "(4.3)"
      ]
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6781,
          7.2381,
          6.5695,
          7.2383,
          6.5695,
          7.5728,
          1.6781,
          7.5727
        ]
      }
    ]
  },
  {
    "content": "By using nonlinear basis functions, we allow the function y(x, w) to be a non- linear function of the input vector x. Functions of the form (4.2) are called linear models, however, because they are linear in w. It is this linearity in the parameters that will greatly simplify the analysis of this class of models. However, it also leads to some significant limitations.",
    "metadata": {
      "page_number": 112,
      "section_heading": "4.1. Linear Regression",
      "subsection_heading": "4.1.1 Basis functions",
      "page_header": "4. SINGLE-LAYER NETWORKS: REGRESSION",
      "figure_references": [],
      "formula_references": [
        "(4.2)"
      ]
    },
    "locations": [
      {
        "page": 2,
        "polygon": [
          1.6763,
          7.5729,
          6.5709,
          7.5585,
          6.5733,
          8.3841,
          1.6787,
          8.3984
        ]
      }
    ]
  }
]